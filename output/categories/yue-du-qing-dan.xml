<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>mklf (文章分类：阅读清单)</title><link>http://blog.fangli.org/</link><description></description><atom:link href="http://blog.fangli.org/categories/yue-du-qing-dan.xml" rel="self" type="application/rss+xml"></atom:link><language>zh_cn</language><lastBuildDate>Fri, 12 Jan 2018 16:16:05 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>本周阅读 2017年07月3日</title><link>http://blog.fangli.org/posts/ben-zhou-yue-du-2017nian-07yue-3ri/</link><dc:creator>Frank Lee</dc:creator><description>&lt;div&gt;&lt;h4&gt;&lt;a href="http://www.bjt.name/2017/07/interview-xiamen"&gt;1. 饭桌上的闲聊&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;业务知识在我们平时的学习生活中是碰不到的，我们该怎么获取相关的知识呢？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;多认识人，多去看、多去想。多认识人就不必多说重要性了。举个多思考的例子：我是哔哩哔哩的重度用户，在逛B站的过程中就会去想，这个系统的设计，模块的关系，以及对应算法怎么去做的；还有网易云音乐，它每个环节的设计，比如用户的评论环节，它能收集到什么样的数据，它的算法能怎么做，数据收集的机制有没有可能做一些改变？&lt;/p&gt;
&lt;p&gt;我认为这是心智的一种锻炼，一开始可能会比较吃力，但你要持续去锻炼这个能力，你要不停去抽象。碰到的问题能不能把它抽象成一个数据问题、数学模型和建模问题。这个能力需要经常去锻炼。早年我觉得哪些数据可能有点用，就会写爬虫去网上爬，爬下来之后就开始折腾自己的一些想法，这个爱好对我后面的工作帮助很大。总结下：你要知道怎样去收集数据，收集数据之后，怎么用这个数据做出一些结论性的内容。学生期间不用特意去追求做所谓的有价值的东西，有兴趣好玩，追随自己内心就可以了。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/div&gt;</description><category>阅读清单</category><guid>http://blog.fangli.org/posts/ben-zhou-yue-du-2017nian-07yue-3ri/</guid><pubDate>Mon, 03 Jul 2017 03:22:53 GMT</pubDate></item><item><title>本周阅读 2017年06月23日</title><link>http://blog.fangli.org/posts/ben-zhou-yue-du-2017nian-06yue-23ri/</link><dc:creator>Frank Lee</dc:creator><description>&lt;div&gt;&lt;h4&gt;&lt;a href="https://devblogs.nvidia.com/parallelforall/unified-memory-cuda-beginners/"&gt;1.Unified Memory for CUDA Beginners&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;一个简单的程序：用 Unified Memory 创建两个向量，在 CPU 上进行初始化，然后用 GPU kernel 计算向量加法。作者发现在 Kepler 架构的 K80 上，向量加法的 kernel 带宽能达到 134GB/s，而在 Pascal 架构的 Tesla P100 上却只有 6GB/s。这是什么原因造成的呢？&lt;/p&gt;
&lt;p&gt;在 Pascal 架构以前， Unified Memory 在创建时会在 GPU 中分配显存，设置好页表等初始化操作。当 CPU 代码访问这片显存时，显卡驱动会把显存中的内容拷贝到内存中 (会有CPU页错误)。此后如果 GPU 又需要访问这片内存，驱动会先把&lt;strong&gt;整块内存&lt;/strong&gt;拷贝到GPU，然后再启动kernel。也就是说内存拷贝的时间是不计入kernel 运行时间的。&lt;/p&gt;
&lt;p&gt;Pascal 架构的 GPU 增加了硬件以提供对 Unified Memory 的支持。在调用&lt;code&gt;cudaMallocManaged()&lt;/code&gt;时并不会真正在显存中分配内存。内存真正的分配被延迟到CPU 或者GPU 访问它的时候。由于支持页错误和页的移动(migration)，Pascal GPU 的kernel在访问一个内存中的 Unified Memory 时不需要提前把内存中的数据拷贝到显存中，而是在 kernel 中访问内存时才按页拷贝(当然会有数据预取减少页错误)。这种内存访问方式对于只利用部分内存的应用，比如对稀疏矩阵的某些操作，只需要在内存和显存间传输需要读写的部分数据。
&lt;/p&gt;&lt;p&gt;&lt;a href="http://blog.fangli.org/posts/ben-zhou-yue-du-2017nian-06yue-23ri/"&gt;更多…&lt;/a&gt; (剩余 1 分钟去阅读)&lt;/p&gt;&lt;/div&gt;</description><category>阅读清单</category><guid>http://blog.fangli.org/posts/ben-zhou-yue-du-2017nian-06yue-23ri/</guid><pubDate>Fri, 23 Jun 2017 02:11:05 GMT</pubDate></item></channel></rss>